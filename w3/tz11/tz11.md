# 挑战11：将仓库信息存入数据库

## 介绍

我们希望获取实验楼的所有 Github 仓库列表，并将数据存入数据库中，爬取的目标页面是:

```
https://github.com/shiyanlou?tab=repositories

```

注意这个页面下面有4个分页，需要爬取每个页面中的仓库名称和更新时间，并将结果存入 MySQL 数据库中。

首先需要按照先前实验中学习的知识启动 MySQL 服务：

```
sudo service mysql start

```

然后登陆 MySQL（root用户密码为空），并创建数据库 shiyanlougithub：

```
mysql > create database shiyanlougithub;

```

挑战中需要使用 sqlalchemy 创建数据库表 `repositories`，并连接数据库，表中的内容至少包含下面内容，存储的格式：

```
class Repository(Base):
    __tablename__ = 'repositories'
    id = Column(Integer, primary_key=True)
    name = Column(String(64))
    update_time = Column(DateTime)

```

注意更新时间的信息并没有展示在页面上，但存在于页面的源代码中，需要你自己在浏览器中检查页面的源代码分析获取。

## 目标

1. 爬取的数据必须放在 `shiyanlougithub` 数据库的 `repositories` 表中
2. 本次挑战的检测脚本只查看结果，即数据库的 `repositories` 表的数据是否准确

## 提示语

1. 挑战环境中如果没有安装 scrapy 或 sqlalchemy，请自己按照实验介绍的方法安装
2. 可以在自己本地的浏览器中进行页面分析，尤其注意指定格式的更新时间在页面中的位置
3. 可以选择使用 CSS 或 XPATH 数据提取器
4. 注意分页的处理，可以参考第一个实验中使用 URL 中 `{}` 的方法处理分页
5. scrapy 默认遵守 robot.txt 禁止爬取的要求，在 Github 的页面中是不会爬取的，可以在 settings.py 设置中将下面的选项设置为 False：

```
ROBOTSTXT_OBEY = False

```

## 知识点

- Scrapy 项目框架
- 分析网页元素字段
- SQLAlchemy 定义数据模型
- 连接数据库
- 创建 Scrapy 项目
- 创建爬虫
- Item 容器
- Item Pipeline
- Models 创建表
- 保存 Item 到数据库