# 挑战12

## 爬取仓库的提交、分支、版本

### 介绍

本挑战基于上一个挑战的内容，补充新的数据到爬取的表中。在本次挑战中，数据库中需要包含每个仓库提交（commits）、分支（branch）、发布版本（realeases）的数量，这些信息都可以在仓库自己的页面中查看到，例如下面这个页面中代码上方就有这三部分数据：

![此处输入图片的描述](https://dn-anything-about-doc.qbox.me/document-uid13labid3708timestamp1506332765847.png/wm)

仓库列表爬取的目标页面是:

```
https://github.com/shiyanlou?tab=repositories

```

注意这个页面下面有4个分页，需要爬取每个页面中的仓库名称和更新时间，并将结果存入 MySQL 数据库中。

首先需要按照先前实验中学习的知识启动 MySQL 服务：

```
sudo service mysql start

```

然后登陆 MySQL（root用户密码为空），并创建数据库 shiyanlougithub：

```
mysql > create database shiyanlougithub;

```

挑战中需要使用 sqlalchemy 创建数据库表 `repositories`，并连接数据库，表中的内容至少包含下面内容，存储的格式：

```
class Repository(Base):
    __tablename__ = 'repositories'
    id = Column(Integer, primary_key=True)
    name = Column(String(64))
    update_time = Column(DateTime)
    commits = Column(Integer)
    branches = Column(Integer)
    releases = Column(Integer)

```

注意更新时间的信息并没有展示在页面上，但存在于页面的源代码中，需要你自己在浏览器中检查页面的源代码分析获取。

### 目标

1. 爬取的数据必须放在 `shiyanlougithub` 数据库的 `repositories` 表中
2. 本次挑战的检测脚本只查看结果，即数据库的 `repositories` 表的数据是否准确

### 提示语

1. 挑战环境中如果没有安装 scrapy 或 sqlalchemy，请自己按照实验介绍的方法安装
2. 可以在自己本地的浏览器中进行页面分析，尤其注意指定格式的更新时间在页面中的位置
3. 可以选择使用 CSS 或 XPATH 数据提取器
4. 注意分页的处理，可以参考第一个实验中使用 URL 中 `{}` 的方法处理分页
5. 注意需要使用多个页面构建 Item，仓库名称和更新时间从 `https://github.com/shiyanlou?tab=repositories` 页面获取，而其他的提交信息等需要从 `https://github.com/shiyanlou/xxxx` 这样的仓库页面获取并存储到数据库中的同一个表中
6. 注意页面的数字字符串有可能有这种形式 `2,412`，所以在转化成整数的时候需要去掉逗号
7. scrapy 默认遵守 robot.txt 禁止爬取的要求，在 Github 的页面中是不会爬取的，可以在 settings.py 设置中将下面的选项设置为 False：

```
ROBOTSTXT_OBEY = False

```

### 知识点

- Scrapy 项目框架
- 分析网页元素字段
- SQLAlchemy 定义数据模型
- 连接数据库
- 创建 Scrapy 项目
- 创建爬虫
- Item 容器
- Item Pipeline
- Models 创建表
- 保存 Item 到数据库
- 组成 item 的数据在多个页面